{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PromptLearner(nn.Module):\n",
    "    def __init__(self, class_names: list, n_context: int, model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.class_names = class_names\n",
    "        self.number_of_classes = len(self.class_names)\n",
    "        self.positive_tokens = n_context\n",
    "        self.negative_tokens = n_context\n",
    "        self.token_dimension = 768 #model.ln_final.weight.shape[0]\n",
    "\n",
    "        print(self.token_dimension)\n",
    "\n",
    "        self.normal_prompt = [ \"object\" ]\n",
    "        self.abnormal_prompt = [ f\"{cls} object\" for cls in class_names ]\n",
    "\n",
    "        self.normal_prompt_length = len(self.normal_prompt)\n",
    "        self.abnormal_prompt_length = len(self.abnormal_prompt)\n",
    "\n",
    "        print('initilizing contexts')\n",
    "\n",
    "        positive_context_vectors = torch.empty(1, self.normal_prompt_length, self.positive_tokens, self.token_dimension)\n",
    "        negative_context_vectors = torch.empty(1, self.abnormal_prompt_length, self.negative_tokens, self.token_dimension)\n",
    "\n",
    "        nn.init.normal_(positive_context_vectors, std=0.02)\n",
    "        nn.init.normal_(negative_context_vectors, std=0.02)\n",
    "        placeholder = \" \".join([\"X\"] * self.positive_tokens)\n",
    "        self.compount_prompts_depth = 4\n",
    "        self.compound_prompts_text = nn.ParameterList([nn.Parameter(torch.empty(4, self.token_dimension))\n",
    "                                                       for _ in range(9)])\n",
    "        \n",
    "        for single_token in self.compound_prompts_text:\n",
    "            print(single_token.shape)\n",
    "            nn.init.normal_(single_token, std =0.02)\n",
    "\n",
    "        positive_tokens = nn.Parameter(positive_context_vectors)\n",
    "        negative_tokens = nn.Parameter(negative_context_vectors)\n",
    "\n",
    "        normal_prompt = [ placeholder + \" \" + template for template in self.normal_prompt ]\n",
    "        anomaly_prompt = [ placeholder + \" \" + template for template in self.abnormal_prompt]\n",
    "\n",
    "        print(normal_prompt, anomaly_prompt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "initilizing contexts\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "['X X X X X X X X X X X X object'] ['X X X X X X X X X X X X bent object', 'X X X X X X X X X X X X cut object', 'X X X X X X X X X X X X scratch object']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptLearner(\n",
       "  (compound_prompts_text): ParameterList(\n",
       "      (0): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (1): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (2): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (3): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (4): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (5): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (6): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (7): Parameter containing: [torch.float32 of size 4x768]\n",
       "      (8): Parameter containing: [torch.float32 of size 4x768]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt  = PromptLearner(['bent', 'cut', 'scratch'], 12, 0)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 27 13:39:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A40                     On  |   00000000:A3:00.0 Off |                    0 |\n",
      "|  0%   29C    P8             21W /  300W |       4MiB /  46068MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask shape: torch.Size([200, 200])\n",
      "tensor([[ True, False, False,  ...,  True,  True,  True],\n",
      "        [ True,  True, False,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def create_task_prompt_attention_mask(num_tasks, num_patches):\n",
    "    \"\"\"\n",
    "    Creates an attention mask to block preceding task prompts from \n",
    "    attending to subsequent task prompts.\n",
    "    \n",
    "    Args:\n",
    "        num_tasks (int): Number of task prompts (t).\n",
    "        num_patches (int): Number of image patches (N).\n",
    "    \n",
    "    Returns:\n",
    "        mask (torch.Tensor): Attention mask of shape [t + N + 1, t + N + 1].\n",
    "                            `False` means \"block attention\".\n",
    "    \"\"\"\n",
    "    total_tokens = num_tasks + num_patches + 1  # +1 for [CLS]\n",
    "    \n",
    "    # Initialize mask as all True (no blocking)\n",
    "    mask = torch.ones((total_tokens, total_tokens), dtype=torch.bool)\n",
    "    \n",
    "    # Block preceding tasks from attending to subsequent tasks (lower triangular)\n",
    "    for i in range(num_tasks):\n",
    "        for j in range(i + 1, num_tasks):\n",
    "            mask[i, j] = False  # Prevents task i from attending to task j\n",
    "    \n",
    "    # Allow all prompts to attend to patches + [CLS]\n",
    "    mask[:num_tasks, num_tasks:] = True\n",
    "    \n",
    "    # Allow patches + [CLS] to attend to everything (standard ViT behavior)\n",
    "    mask[num_tasks:, :] = True\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Example usage\n",
    "num_tasks = 3  # Number of task prompts (e.g., p1, p2, p3)\n",
    "num_patches = 196  # For a 14x14 patch grid (224x224 image)\n",
    "mask = create_task_prompt_attention_mask(num_tasks, num_patches)\n",
    "\n",
    "print(\"Attention mask shape:\", mask.shape)\n",
    "print(mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pipe_fryum/Data/Images/Anomaly/000.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/000.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/001.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/001.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/002.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/002.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/003.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/003.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/004.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/004.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/005.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/005.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/006.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/006.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/007.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/007.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/008.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/008.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/009.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/009.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/010.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/010.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/011.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/011.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/012.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/012.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/013.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/013.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/014.JPG', 'burnt', 'pipe_fryum/Data/Masks/Anomaly/014.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/015.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/015.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/016.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/016.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/017.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/017.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/018.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/018.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/019.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/019.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/020.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/020.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/021.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/021.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/022.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/022.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/023.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/023.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/024.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/024.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/025.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/025.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/026.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/026.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/027.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/027.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/028.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/028.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/029.JPG', 'corner and edge breakage', 'pipe_fryum/Data/Masks/Anomaly/029.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/030.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/030.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/031.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/031.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/032.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/032.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/033.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/033.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/034.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/034.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/035.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/035.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/036.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/036.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/037.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/037.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/038.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/038.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/039.JPG', 'different colour spot', 'pipe_fryum/Data/Masks/Anomaly/039.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/040.JPG', 'middle breakage,small scratches,small cracks', 'pipe_fryum/Data/Masks/Anomaly/040.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/041.JPG', 'middle breakage,small cracks', 'pipe_fryum/Data/Masks/Anomaly/041.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/042.JPG', 'middle breakage,small cracks', 'pipe_fryum/Data/Masks/Anomaly/042.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/043.JPG', 'middle breakage,small cracks', 'pipe_fryum/Data/Masks/Anomaly/043.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/044.JPG', 'middle breakage,small cracks', 'pipe_fryum/Data/Masks/Anomaly/044.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/045.JPG', 'middle breakage,small scratches,small cracks', 'pipe_fryum/Data/Masks/Anomaly/045.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/046.JPG', 'middle breakage,small scratches,small cracks', 'pipe_fryum/Data/Masks/Anomaly/046.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/047.JPG', 'middle breakage,small cracks', 'pipe_fryum/Data/Masks/Anomaly/047.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/048.JPG', 'middle breakage,small cracks', 'pipe_fryum/Data/Masks/Anomaly/048.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/049.JPG', 'middle breakage,small scratches,small cracks', 'pipe_fryum/Data/Masks/Anomaly/049.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/050.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/050.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/051.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/051.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/052.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/052.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/053.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/053.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/054.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/054.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/055.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/055.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/056.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/056.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/057.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/057.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/058.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/058.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/059.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/059.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/060.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/060.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/061.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/061.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/062.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/062.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/063.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/063.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/064.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/064.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/065.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/065.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/066.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/066.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/067.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/067.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/068.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/068.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/069.JPG', 'similar colour spot', 'pipe_fryum/Data/Masks/Anomaly/069.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/070.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/070.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/071.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/071.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/072.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/072.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/073.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/073.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/074.JPG', 'burnt,small scratches', 'pipe_fryum/Data/Masks/Anomaly/074.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/075.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/075.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/076.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/076.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/077.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/077.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/078.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/078.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/079.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/079.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/080.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/080.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/081.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/081.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/082.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/082.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/083.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/083.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/084.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/084.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/085.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/085.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/086.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/086.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/087.JPG', 'similar colour spot,small scratches', 'pipe_fryum/Data/Masks/Anomaly/087.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/088.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/088.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/089.JPG', 'small scratches', 'pipe_fryum/Data/Masks/Anomaly/089.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/090.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/090.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/091.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/091.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/092.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/092.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/093.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/093.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/094.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/094.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/095.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/095.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/096.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/096.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/097.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/097.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/098.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/098.png']\n",
      "['pipe_fryum/Data/Images/Anomaly/099.JPG', 'stuck together', 'pipe_fryum/Data/Masks/Anomaly/099.png']\n",
      "✅ Grouping complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "# Base path setup\n",
    "obj = \"pipe_fryum\"\n",
    "base_dir = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_v2\"\n",
    "image_base = os.path.join(base_dir, f\"{obj}/Data/Images/Anomaly\")\n",
    "mask_base = os.path.join(base_dir, f\"{obj}/Data/Masks/Anomaly\")\n",
    "output_base = os.path.join(base_dir, f\"{obj}/Data/Images/Anomaly\")\n",
    "\n",
    "# Path to the annotation file\n",
    "annotation_path = os.path.join(base_dir, f\"{obj}/image_anno.csv\" ) # Replace with the actual path if different\n",
    "\n",
    "# Create folders and copy files\n",
    "with open(annotation_path, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        if len(row) < 3 or not row[2].strip():\n",
    "            continue\n",
    "        print(row)\n",
    "        image_path, labels, mask_path = row\n",
    "        labels = [label.strip() for label in labels.split(\",\")]\n",
    "\n",
    "        for label in labels:\n",
    "            img_target_dir = os.path.join(output_base, label)\n",
    "            mask_target_dir = os.path.join(output_base, \"Masks\", label)\n",
    "            os.makedirs(img_target_dir, exist_ok=True)\n",
    "            os.makedirs(mask_target_dir, exist_ok=True)\n",
    "\n",
    "            # Copy image\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            shutil.copy2(os.path.join(base_dir, image_path), os.path.join(img_target_dir, image_filename))\n",
    "\n",
    "            # Copy mask\n",
    "            mask_filename = os.path.basename(mask_path)\n",
    "            shutil.copy2(os.path.join(base_dir, mask_path), os.path.join(mask_target_dir, mask_filename))\n",
    "\n",
    "print(\"✅ Grouping complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annotations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(binary_mask_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Move images and masks\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     17\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mnext\u001b[39m(reader)  \u001b[38;5;66;03m# Skip header\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/adaware/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'annotations.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "# Paths\n",
    "base_dir = \"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_v2/capsules\"\n",
    "annotation_path = \"annotations.csv\"\n",
    "binary_img_dir = os.path.join(base_dir, \"Data/Binary/Images\")\n",
    "binary_mask_dir = os.path.join(base_dir, \"Data/Binary/Masks\")\n",
    "\n",
    "# Create binary folders if they don't exist\n",
    "os.makedirs(binary_img_dir, exist_ok=True)\n",
    "os.makedirs(binary_mask_dir, exist_ok=True)\n",
    "\n",
    "# Move images and masks\n",
    "with open(annotation_path, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # Skip header\n",
    "\n",
    "    for row in reader:\n",
    "        if len(row) < 3 or not row[2].strip():\n",
    "            continue  # Skip normal cases (no mask)\n",
    "\n",
    "        image_path, _, mask_path = row\n",
    "\n",
    "        full_image_path = os.path.join(base_dir, image_path)\n",
    "        full_mask_path = os.path.join(base_dir, mask_path)\n",
    "\n",
    "        # Move image\n",
    "        shutil.move(full_image_path, os.path.join(binary_img_dir, os.path.basename(image_path)))\n",
    "\n",
    "        # Move mask\n",
    "        shutil.move(full_mask_path, os.path.join(binary_mask_dir, os.path.basename(mask_path)))\n",
    "\n",
    "print(\"✅ All anomaly images and masks moved to Binary folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from collections import defaultdict\n",
    "cls_name = \"pipe_fryum\"\n",
    "img_root = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype/{cls_name}/Data/Anomaly\"\n",
    "mask_root = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype/{cls_name}/Data/Anomaly/Masks\"\n",
    "\n",
    "output_root = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype/{cls_name}/Data/Anomaly_grouped\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "image_defects = defaultdict(list)\n",
    "for defect_type in os.listdir(img_root):\n",
    "    if defect_type == \"Masks\":\n",
    "        continue\n",
    "    defect_path = os.path.join(img_root, defect_type)\n",
    "    if not os.path.isdir(defect_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(defect_path):\n",
    "        if not img_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        image_folder = os.path.join(output_root, base_name)\n",
    "        os.makedirs(os.path.join(image_folder, 'masks'), exist_ok=True)\n",
    "\n",
    "        dest_img_path = os.path.join(image_folder, \"image.jpg\")\n",
    "        if not os.path.exists(dest_img_path):\n",
    "            shutil.copy(os.path.join(defect_path, img_name), dest_img_path)\n",
    "        mask_path = os.path.join(mask_root, defect_type, base_name + \".png\")\n",
    "        if os.path.exists(mask_path):\n",
    "            dst_mask_path = os.path.join(image_folder, \"masks\", defect_type.replace(\" \", \"_\") + \".png\")\n",
    "            shutil.copy(mask_path, dst_mask_path)\n",
    "\n",
    "        image_defects[base_name].append(defect_type)\n",
    "\n",
    "# for img_name, defects in image_defects.items():\n",
    "#     defect_file = os.path.join(output_root, img_name, \"defects.txt\")\n",
    "#     with open(defect_file, \"w\") as f:\n",
    "#         f.write(\"\\n\".join(defects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '001', '002', '003', '004', '007', '009', '010', '014', '016', '017', '019', '022', '029', '031', '033', '034', '035', '036', '039', '040', '042', '043', '045', '047', '050', '054', '056', '058', '060', '064', '070', '071', '074', '075', '078', '079', '080', '081', '082', '084', '085', '086', '087', '088', '092', '095', '097', '098']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "object = \"pcb4\"\n",
    "mask_root = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype/{object}/Data/Anomaly_grouped\"\n",
    "file_names = []\n",
    "for img in os.listdir(mask_root):\n",
    "    img_path = os.path.join(mask_root, img)\n",
    "    mask_path = os.path.join(img_path, \"masks\")\n",
    "    if len(os.listdir(mask_path)) > 1:\n",
    "        file_names.append(img)\n",
    "\n",
    "print((sorted(file_names)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "object = \"fryu\"\n",
    "img_no = \"008\"\n",
    "mask_root = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype/{object}/Data/Anomaly_grouped/{img_no}/masks\"\n",
    "realtive_opath = \"data/visa_multitiype/chewinggum/Data/Anomaly_grouped/008/masks/missing.png\"\n",
    "# Load a binary image (0 and 1) – if needed, multiply by 255\n",
    "img_mask = cv2.imread(os.path.join(mask_root, \"missing.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "img_np = np.array(img_mask).astype(np.uint8)\n",
    "#img = (np.ones((400, 400), dtype=np.uint8)) * 255  # Example 1s image\n",
    " \n",
    "# Mouse callback to draw\n",
    "def draw_mask(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cv2.circle(img_np, (x, y), 20, 0, -1)  # Draw a black (0) circle\n",
    " \n",
    "cv2.namedWindow('Mask')\n",
    "cv2.setMouseCallback('Mask', draw_mask)\n",
    " \n",
    "while True:\n",
    "    cv2.imshow('Mask', img_np)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC to exit\n",
    "        break\n",
    " \n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# Convert to binary 0/1 again if needed\n",
    "cv2.imwrite(os.path.join(mask_root, \"crack.png\"), img_np)\n",
    "#img = img // 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved to visa_candle_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "object = \"candle\"\n",
    "\n",
    "base_dir = f\"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype/{object}/Data\"\n",
    "relative_path = f\"{object}/Data\"\n",
    "normal_dir = os.path.join(base_dir, \"Normal\")\n",
    "anomaly_dir = os.path.join(base_dir, \"Anomaly_grouped\")\n",
    "\n",
    "# Output dictionary\n",
    "dataset_json = {\n",
    "    \"train\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "# Gather all normal images\n",
    "normal_images = [\n",
    "    os.path.join(normal_dir, fname)\n",
    "    for fname in os.listdir(normal_dir)\n",
    "    if fname.lower().endswith((\".jpg\", \".png\"))\n",
    "]\n",
    "\n",
    "# Split normal images into train (80%) and test (20%)\n",
    "train_normals, test_normals = train_test_split(normal_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add to train\n",
    "for img_path in train_normals:\n",
    "    rel_path = os.path.relpath(img_path, base_dir)\n",
    "    dataset_json[\"train\"].append({\n",
    "        \"image_path\": os.path.join(relative_path, rel_path),\n",
    "        \"defects\": {}\n",
    "    })\n",
    "\n",
    "# Add 20% normal to test\n",
    "for img_path in test_normals:\n",
    "    dataset_json[\"test\"].append({\n",
    "        \"image_path\": os.path.join(relative_path, rel_path),\n",
    "        \"defects\": {}\n",
    "    })\n",
    "\n",
    "# Add all anomaly samples to test\n",
    "for sample_id in os.listdir(anomaly_dir):\n",
    "    sample_path = os.path.join(anomaly_dir, sample_id)\n",
    "    image_path = os.path.join(sample_path, \"image.jpg\")\n",
    "    masks_dir = os.path.join(sample_path, \"masks\")\n",
    "\n",
    "    # Skip if image or mask folder is missing\n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "\n",
    "    defects = {}\n",
    "    if os.path.isdir(masks_dir):\n",
    "        for mask_file in os.listdir(masks_dir):\n",
    "            if mask_file.lower().endswith(\".png\"):\n",
    "                defect_name = os.path.splitext(mask_file)[0]  # e.g., \"missing\"\n",
    "                mask_path = os.path.join(masks_dir, mask_file)\n",
    "                rel_mask_path = os.path.join(relative_path, os.path.relpath(mask_path, base_dir))\n",
    "                defects[defect_name] = rel_mask_path\n",
    "    rel_image_path = os.path.join(relative_path, os.path.relpath(image_path, base_dir))\n",
    "\n",
    "    dataset_json[\"test\"].append({\n",
    "        \"image_path\": rel_image_path,\n",
    "        \"defects\": defects\n",
    "    })\n",
    "\n",
    "# Save the final JSON\n",
    "output_path = \"visa_candle_dataset.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(dataset_json, f, indent=2)\n",
    "\n",
    "print(f\"JSON saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved JSON to visa_dataset_split_by_phase.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---- CONFIGURATION ----\n",
    "root_dir = \"/fs/scratch/rb_bd_dlp_rng_dl01_cr_ICT_employees/students/nan1rng/test/data/visa_multitiype\"  # Top-level directory containing class folders (e.g., candle, capsule)\n",
    "json_relative_root = \"visa_multitiype\"  # Prefix to preserve in saved paths\n",
    "output_json_path = \"visa_dataset_split_by_phase.json\"\n",
    "# ------------------------\n",
    "strip_prefix = os.path.abspath(\"data/visa_multitiype\")\n",
    "# Final JSON structure\n",
    "dataset_json = {\n",
    "    \"train\": {},\n",
    "    \"test\": {}\n",
    "}\n",
    "\n",
    "# Iterate over each class directory\n",
    "for cls_name in os.listdir(root_dir):\n",
    "    cls_path = os.path.join(root_dir, cls_name)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "\n",
    "    data_path = os.path.join(cls_path, \"Data\")\n",
    "    normal_dir = os.path.join(data_path, \"Normal\")\n",
    "    anomaly_dir = os.path.join(data_path, \"Anomaly_grouped\")\n",
    "\n",
    "    train_entries = []\n",
    "    test_entries = []\n",
    "\n",
    "    # --- Normal Images ---\n",
    "    if os.path.isdir(normal_dir):\n",
    "        normal_images = [\n",
    "            os.path.join(normal_dir, fname)\n",
    "            for fname in os.listdir(normal_dir)\n",
    "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ]\n",
    "\n",
    "        # Split: 80% train, 20% test\n",
    "        train_normals, test_normals = train_test_split(normal_images, test_size=0.2, random_state=42)\n",
    "\n",
    "        for img_path in train_normals:\n",
    "            rel_path = os.path.relpath(img_path, strip_prefix).replace(\"\\\\\", \"/\")\n",
    "            train_entries.append({\n",
    "                \"image_path\": rel_path,\n",
    "                \"defects\": {},\n",
    "                \"Anomaly\": 0\n",
    "            })\n",
    "\n",
    "        for img_path in test_normals:\n",
    "            rel_path = os.path.relpath(img_path, strip_prefix).replace(\"\\\\\", \"/\")\n",
    "            test_entries.append({\n",
    "                \"image_path\": rel_path,\n",
    "                \"defects\": {},\n",
    "                \"Anomaly\": 0\n",
    "            })\n",
    "\n",
    "    # --- Anomalous Images ---\n",
    "    if os.path.isdir(anomaly_dir):\n",
    "        for sample_id in os.listdir(anomaly_dir):\n",
    "            sample_path = os.path.join(anomaly_dir, sample_id)\n",
    "            image_path = os.path.join(sample_path, \"image.jpg\")\n",
    "            masks_dir = os.path.join(sample_path, \"masks\")\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                continue\n",
    "\n",
    "            defects = {}\n",
    "            if os.path.isdir(masks_dir):\n",
    "                for mask_file in os.listdir(masks_dir):\n",
    "                    if mask_file.lower().endswith(\".png\"):\n",
    "                        defect_name = os.path.splitext(mask_file)[0]\n",
    "                        mask_path = os.path.join(masks_dir, mask_file)\n",
    "                        rel_mask_path = os.path.relpath(mask_path, strip_prefix).replace(\"\\\\\", \"/\")\n",
    "                        defects[defect_name] = rel_mask_path\n",
    "\n",
    "            rel_image_path = os.path.relpath(image_path, strip_prefix).replace(\"\\\\\", \"/\")\n",
    "            test_entries.append({\n",
    "                \"image_path\": rel_image_path,\n",
    "                \"defects\": defects,\n",
    "                \"Anomaly\": 1\n",
    "            })\n",
    "\n",
    "    # Store in global dictionary\n",
    "    if train_entries:\n",
    "        dataset_json[\"train\"][cls_name] = train_entries\n",
    "    if test_entries:\n",
    "        dataset_json[\"test\"][cls_name] = test_entries\n",
    "\n",
    "# Save to JSON file\n",
    "with open(output_json_path, \"w\") as f:\n",
    "    json.dump(dataset_json, f, indent=2)\n",
    "\n",
    "print(f\"Saved JSON to {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
